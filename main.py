import os, whisper, yt_dlp, shutil, time
from openai import OpenAI
import gradio as gr

def process_video_batch(api_key, video_urls_str):
    """æ‰¹é‡å¤„ç†é€»è¾‘ï¼šå¾ªç¯æ¯ä¸€ä¸ªé“¾æ¥"""
    final_key = api_key if api_key and "sk-" in api_key else "sk-placeholder"
    
    # 1. æ‹†åˆ†é“¾æ¥ï¼šæŒ‰æ¢è¡Œç¬¦æ‹†åˆ†ï¼Œå»æ‰ç©ºæ ¼
    urls = [u.strip() for u in video_urls_str.split('\n') if u.strip()]
    
    if "placeholder" in final_key:
        yield "âŒ é”™è¯¯ï¼šè¯·åœ¨ç•Œé¢è¾“å…¥æœ‰æ•ˆçš„ API_KEY", None
        return
    if not urls:
        yield "âŒ é”™è¯¯ï¼šè¯·è¾“å…¥è‡³å°‘ä¸€ä¸ªé“¾æ¥ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰", None
        return

    client = OpenAI(api_key=final_key, base_url="https://dashscope.aliyuncs.com/compatible-mode/v1")
    all_summary_report = ""
    all_segmented_files = []

    for idx, url in enumerate(urls):
        header = f"### ğŸ“º æ­£åœ¨æ”¶å‰²ç¬¬ ({idx+1}/{len(urls)}): {url}\n"
        yield all_summary_report + header + "æ­£åœ¨å¯åŠ¨...", all_segmented_files
        
        try:
            # 2. ä¸ºæ¯ä¸ªè§†é¢‘åˆ›å»ºç‹¬ç«‹çš„æ–‡ä»¶åï¼Œé˜²æ­¢äº’ç›¸è¦†ç›–
            audio_file = f"temp_audio_{idx}.m4a"
            txt_cache = f"raw_{idx}.txt"
            seg_file = f"video_{idx+1}_åˆ†æ®µåŸç¨¿.txt"

            # --- A. è·å–éŸ³é¢‘ ---
            if not os.path.exists(audio_file):
                yield all_summary_report + header + "ğŸ“¥ æ­£åœ¨æŠ“å–éŸ³é¢‘...", all_segmented_files
                audio_opts = {
                    'format': 'm4a/bestaudio/best',
                    'outtmpl': f'temp_audio_{idx}.%(ext)s',
                    'postprocessors': [{'key': 'FFmpegExtractAudio','preferredcodec': 'm4a'}],
                    'quiet': True
                }
                with yt_dlp.YoutubeDL(audio_opts) as ydl:
                    ydl.download([url])

            # --- B. è¯­éŸ³è¯†åˆ« ---
            if os.path.exists(txt_cache):
                with open(txt_cache, "r", encoding="utf-8") as f:
                    content_text = f.read()
            else:
                yield all_summary_report + header + "ğŸ™ï¸ Whisper å¬å†™ä¸­...", all_segmented_files
                import torch
                device = "cuda" if torch.cuda.is_available() else "cpu"
                model = whisper.load_model("base", device=device) 
                result = model.transcribe(audio_file)
                content_text = result['text']
                with open(txt_cache, "w", encoding="utf-8") as f:
                    f.write(content_text)

            # --- C. åŸæ„åˆ†æ®µ (å…³é”®ï¼šä¸é˜‰å‰²) ---
            yield all_summary_report + header + "ğŸ“‘ æ­£åœ¨åŸæ„åˆ†æ®µ (ä¿çœŸæ¨¡å¼)...", all_segmented_files
            split_prompt = f"ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„é€Ÿè®°å‘˜ã€‚è¯·å¯¹ä»¥ä¸‹æ–‡ç¨¿è¿›è¡Œã€ä»…åˆ†æ®µä¸åŠ æ ‡ç‚¹ã€‘å¤„ç†ï¼Œä¸¥ç¦åˆ å‡ã€æ”¹åŠ¨æˆ–æ¶¦è‰²åŸæ–‡ä»»ä½•è¯è¯­ï¼š\n\n{content_text}"
            
            # ä½¿ç”¨ Turbo æ¨¡å‹è·‘åˆ†æ®µï¼Œé€Ÿåº¦å¿«ä¸”å®¡æ ¸æ¾
            split_res = client.chat.completions.create(model="qwen-turbo", messages=[{"role": "user", "content": split_prompt}])
            segmented_text = split_res.choices[0].message.content
            
            with open(seg_file, "w", encoding="utf-8") as f:
                f.write(segmented_text)
            all_segmented_files.append(seg_file)

            # --- D. æç‚¼å¯¼å›¾ ---
            yield all_summary_report + header + "âœï¸ æ­£åœ¨æç‚¼æ€ç»´å¯¼å›¾å¤§çº²...", all_segmented_files
            map_prompt = f"ä½ æ˜¯ä¸€ä½é¡¶çº§çš„é€»è¾‘åˆ†æå¸ˆã€‚è¯·åŸºäºä»¥ä¸‹åˆ†æ®µæ–‡ç¨¿æå–å¤§çº²å’Œ mermaid mindmap ä»£ç ã€‚è¦æ±‚ï¼šä¸¥æ ¼ä¿ç•™æ ¸å¿ƒè®ºç‚¹ï¼Œç”¨ã€Œã€åŒ…è£¹é‡‘å¥ã€‚\n\næ–‡ç¨¿å†…å®¹ï¼š\n{segmented_text}"
            
            map_res = client.chat.completions.create(model="qwen-plus", messages=[{"role": "user", "content": map_prompt}])
            map_content = map_res.choices[0].message.content

            # ç´¯åŠ æŠ¥å‘Šå†…å®¹
            all_summary_report += f"\n---\n{header}\n{map_content}\n"
            yield all_summary_report, all_segmented_files

        except Exception as e:
            error_msg = f"\nâŒ è§†é¢‘ {idx+1} è¿è¡ŒæŠ¥é”™: {str(e)}\n"
            all_summary_report += error_msg
            yield all_summary_report, all_segmented_files

    yield all_summary_report + "\n\nâœ… æ‰€æœ‰ä»»åŠ¡å¤„ç†å®Œæˆï¼", all_segmented_files

# --- Gradio ç•Œé¢ (æ”¹ä¸ºæ”¯æŒå¤šè¡Œè¾“å…¥) ---
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("# ğŸ“ å¤šé“¾æ¥æ‰¹é‡å­¦æœ¯æ”¶å‰²æœº (åŸæ„ä¸é˜‰å‰²ç‰ˆ)")
    with gr.Row():
        with gr.Column(scale=1):
            api_input = gr.Textbox(label="API KEY", type="password")
            url_input = gr.Textbox(label="è§†é¢‘/æ’­å®¢é“¾æ¥ (æ¯è¡Œä¸€ä¸ª)", lines=5, placeholder="ç²˜è´´å¤šä¸ªé“¾æ¥ï¼Œä¸€è¡Œä¸€ä¸ª...")
            btn = gr.Button("ğŸš€ å¼€å§‹æ‰¹é‡æ”¶å‰²", variant="primary")
            clear_btn = gr.Button("ğŸ§¹ æ¸…ç©ºæ‰€æœ‰ç¼“å­˜")
        with gr.Column(scale=2):
            file_output = gr.File(label="ä¸‹è½½æ‰€æœ‰åˆ†æ®µåŸç¨¿", file_count="multiple")
            output_md = gr.Markdown(label="ç”Ÿæˆçš„æ±‡æ€»æ€»ç»“æŠ¥å‘Š")
    
    btn.click(fn=process_video_batch, inputs=[api_input, url_input], outputs=[output_md, file_output])
    
    def clear_all():
        # æ¸…ç†ç›®å½•ä¸‹æ‰€æœ‰çš„ä¸´æ—¶éŸ³é¢‘ã€æ–‡ç¨¿
        files_to_delete = [f for f in os.listdir() if f.endswith((".m4a", ".txt", ".md"))]
        for f in files_to_delete:
            os.remove(f)
        return "âœ¨ æ‰€æœ‰ç¼“å­˜æ–‡ä»¶å·²æ¸…ç†ã€‚", None
    clear_btn.click(fn=clear_all, outputs=[output_md, file_output])

if __name__ == "__main__":
    demo.launch(share=True, debug=True)
