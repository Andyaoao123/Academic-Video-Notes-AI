import os, whisper, yt_dlp, shutil, time
from openai import OpenAI
import gradio as gr
from pydub import AudioSegment

def call_ai_pipeline(client, harvest_mode, text_content):
    """æå–å‡ºçš„ AI å¤„ç†æ ¸å¿ƒé€»è¾‘"""
    # Step B: æ ‡ç‚¹è¿˜åŸ
    clean_p = f"ä½ æ˜¯ä¸€ä½æ–‡å­—æ•´ç†å¸ˆã€‚è¯·å¯¹ä»¥ä¸‹åŸå§‹è¯­éŸ³æ–‡æœ¬è¿›è¡Œã€æ ‡ç‚¹è¿˜åŸã€‘å’Œã€é€»è¾‘åˆ†æ®µã€‘ï¼Œä¸¥ç¦åˆ å‡æˆ–æ¶¦è‰²åŸæ–‡è¯è¯­ï¼š\n\n{text_content}"
    clean_res = client.chat.completions.create(model="qwen-turbo", messages=[{"role": "user", "content": clean_p}])
    segmented_text = clean_res.choices[0].message.content

    # Step C: æ ¹æ®æ¨¡å¼è¾“å‡º
    if harvest_mode == "é€æ®µç¿»è¯‘å¯¹ç…§":
        trans_p = f"ä»»åŠ¡ï¼šæ–‡æœ¬é€æ®µç¿»è¯‘å¯¹ç…§ã€‚è¦æ±‚ï¼šæ ¼å¼ä¸º [åŸæ–‡æ®µè½]\n[ç¿»è¯‘æ®µè½]\n---ã€‚è¯·ç¿»è¯‘ä»¥ä¸‹å·²åˆ†æ®µæ–‡æœ¬ï¼Œç¡®ä¿ç¿»è¯‘ç²¾å‡†ä¸”ä¸æ”¹å†™åŸæ–‡ï¼š\n\n{segmented_text}"
        res = client.chat.completions.create(model="qwen-plus", messages=[{"role": "user", "content": trans_p}])
        return res.choices[0].message.content
    elif harvest_mode == "é€»è¾‘å¤§çº²æ¨¡å¼":
        map_p = f"ä½ æ˜¯ä¸€ä½é€»è¾‘åˆ†æå¸ˆã€‚è¯·åŸºäºä»¥ä¸‹åˆ†æ®µæ–‡ç¨¿æå–å¤§çº²å’Œmermaid mindmapä»£ç ï¼Œæ ¸å¿ƒè®ºç‚¹ç”¨ã€Œã€åŒ…è£¹ï¼š\n\n{segmented_text}"
        res = client.chat.completions.create(model="qwen-plus", messages=[{"role": "user", "content": map_p}])
        return res.choices[0].message.content
    else:
        return segmented_text

def process_all_in_one(api_key, input_content, harvest_mode):
    final_key = api_key if api_key and "sk-" in api_key else "sk-placeholder"
    if "placeholder" in final_key:
        yield "âŒ é”™è¯¯ï¼šè¯·åœ¨ç•Œé¢è¾“å…¥æœ‰æ•ˆçš„ API_KEY", None
        return
    if not input_content.strip():
        yield "âŒ é”™è¯¯ï¼šè¾“å…¥å†…å®¹ä¸èƒ½ä¸ºç©º", None
        return

    client = OpenAI(api_key=final_key, base_url="https://dashscope.aliyuncs.com/compatible-mode/v1")
    all_summary_report = ""
    all_files = []
    lines = [l.strip() for l in input_content.split('\n') if l.strip()]

    if harvest_mode == "é›…æ€ä½œæ–‡æ•™ç»ƒ":
        yield "âœï¸ è€ƒå®˜æ­£åœ¨ç ”è¯»ä½ çš„å¤§ä½œ...", None
        ielts_p = f"ä»»åŠ¡ï¼šé›…æ€å‰è€ƒå®˜æ·±åº¦æ‰¹æ”¹...\n{input_content}" 
        try:
            res = client.chat.completions.create(model="qwen-plus", messages=[{"role": "user", "content": ielts_p}])
            feedback = res.choices[0].message.content
            f_name = "é›…æ€ä½œæ–‡æ‰¹æ”¹æŠ¥å‘Š.txt"
            with open(f_name, "w", encoding="utf-8") as f: f.write(feedback)
            yield feedback, [f_name]
        except Exception as e: yield f"âŒ æ‰¹æ”¹å¤±è´¥: {str(e)}", None
        return

    for idx, content in enumerate(lines):
        header = f"### ğŸ“º æ­£åœ¨å¤„ç† ({idx+1}/{len(lines)}): {content}\n"
        yield all_summary_report + header + "æ­£åœ¨æ£€æŸ¥/å‡†å¤‡èµ„æº...", all_files
        
        try:
            audio_file = f"temp_audio_{idx}.mp3"
            
            # ã€æ ¸å¿ƒæ”¹è¿› 1ã€‘ï¼šè¯†åˆ«æœ¬åœ°/Drive è·¯å¾„å¹¶è‡ªåŠ¨è½¬ç 
            if content.startswith("/content/"):
                if not os.path.exists(audio_file):
                    yield all_summary_report + header + "ğŸ“‚ æ£€æµ‹åˆ°è·¯å¾„ï¼Œæ­£åœ¨è½¬æ¢éŸ³è½¨...", all_files
                    raw_data = AudioSegment.from_file(content)
                    raw_data.export(audio_file, format="mp3")
            
            # ã€æ ¸å¿ƒæ”¹è¿› 2ã€‘ï¼šå¢åŠ  B ç«™é˜²çˆ¬è¡¥ä¸ä¸‹è½½
            elif not os.path.exists(audio_file):
                yield all_summary_report + header + "ğŸŒ æ­£åœ¨å¯åŠ¨ç½‘ç»œä¸‹è½½ (å¸¦é˜²çˆ¬è¡¥ä¸)...", all_files
                opts = {
                    'format': 'mp3/bestaudio/best',
                    'outtmpl': f'temp_audio_{idx}.%(ext)s',
                    'postprocessors': [{'key': 'FFmpegExtractAudio','preferredcodec': 'mp3'}],
                    'quiet': True,
                    'user_agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36',
                    'referer': 'https://www.bilibili.com/',
                    'nocheckcertificate': True
                }
                with yt_dlp.YoutubeDL(opts) as ydl: ydl.download([content])

            # 2. è§£æéŸ³é¢‘
            audio_data = AudioSegment.from_file(audio_file)
            duration_mins = len(audio_data) / (60 * 1000)
            chunk_length = 20 * 60 * 1000
            chunks = [audio_data[i:i + chunk_length] for i in range(0, len(audio_data), chunk_length)]
            
            video_combined_text = ""
            yield all_summary_report + header + f"ğŸ“¦ å…¨é•¿ {duration_mins:.1f} åˆ†é’Ÿï¼Œå…± {len(chunks)} æ®µã€‚æ£€æŸ¥æ–­ç‚¹...", all_files

            # ã€æ ¸å¿ƒæ”¹è¿› 3ã€‘ï¼šæ™ºèƒ½æ£€æµ‹ GPUï¼ŒæŒ‚äº†å°±è‡ªåŠ¨æ¢ CPU
            import torch
            device = "cuda" if torch.cuda.is_available() else "cpu"
            model = whisper.load_model("base", device=device)

            for c_idx, chunk in enumerate(chunks):
                tmp_out = f"video_{idx+1}_Part_{c_idx+1}.txt"
                segment_divider = f"\n\n--- ğŸ“œ ç¬¬ {c_idx+1} éƒ¨åˆ† (çº¦ {c_idx*20}-{(c_idx+1)*20}min) ---\n\n"

                if os.path.exists(tmp_out):
                    yield all_summary_report + header + f"â© åŠ è½½å·²å­˜æ–­ç‚¹: ç¬¬ {c_idx+1}/{len(chunks)} æ®µ...", all_files
                    with open(tmp_out, "r", encoding="utf-8") as f:
                        processed_chunk_text = f.read()
                    video_combined_text += segment_divider + processed_chunk_text
                    if tmp_out not in all_files: all_files.append(tmp_out)
                    continue 

                chunk_filename = f"temp_{idx}_{c_idx+1}.mp3"
                chunk.export(chunk_filename, format="mp3")
                
                yield all_summary_report + header + f"ğŸ™ï¸ [ç¬¬{c_idx+1}æ®µ] Whisper å¬å†™ä¸­ ({device})...", all_files
                raw_chunk_text = model.transcribe(chunk_filename)['text']
                
                yield all_summary_report + header + f"âœï¸ [ç¬¬{c_idx+1}æ®µ] AI å¤„ç†ä¸­...", all_files
                processed_chunk_text = call_ai_pipeline(client, harvest_mode, raw_chunk_text)
                
                with open(tmp_out, "w", encoding="utf-8") as f: f.write(processed_chunk_text)
                video_combined_text += segment_divider + processed_chunk_text
                all_files.append(tmp_out)
                
                yield all_summary_report + header + video_combined_text, all_files

            final_out_f = f"video_{idx+1}_å®Œæ•´æ”¶å‰²ç¨¿.txt"
            with open(final_out_f, "w", encoding="utf-8") as f: f.write(video_combined_text)
            all_files.append(final_out_f)
            all_summary_report += f"\n---\n{header}\nâœ… å¤„ç†å®Œæˆï¼\n"
            yield all_summary_report, all_files

        except Exception as e:
            all_summary_report += f"\nâŒ æŠ¥é”™: {str(e)}\n"
            yield all_summary_report, all_files

    yield all_summary_report + "\n\nâœ… ä»»åŠ¡å…¨éƒ¨å®Œæˆï¼", all_files

# --- ç•Œé¢éƒ¨åˆ† ---
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("# ğŸ“ å­¦æœ¯å¤šåŠŸèƒ½æ”¶å‰²æœº (å…¨èƒ½è·¯å¾„è¯†åˆ«ç‰ˆ)")
    with gr.Row():
        with gr.Column(scale=1):
            api_input = gr.Textbox(label="API KEY", type="password")
            input_box = gr.Textbox(label="è¾“å…¥åŒºåŸŸ", lines=8, placeholder="å¡«é“¾æ¥ æˆ– å¡« /content/ å¼€å¤´çš„æœ¬åœ°è·¯å¾„")
            mode_radio = gr.Radio(
                choices=["é€»è¾‘å¤§çº²æ¨¡å¼", "é€æ®µæ•´ç†(ä¸ç¿»è¯‘)", "é€æ®µç¿»è¯‘å¯¹ç…§", "é›…æ€ä½œæ–‡æ•™ç»ƒ"], 
                value="é€æ®µæ•´ç†(ä¸ç¿»è¯‘)", 
                label="é€‰æ‹©ä½œæˆ˜æ¨¡å¼"
            )
            btn = gr.Button("ğŸš€ ç«‹å³å¤„ç†", variant="primary")
            clear_btn = gr.Button("ğŸ§¹ æ¸…ç†ç¼“å­˜æ–‡ä»¶")
        with gr.Column(scale=2):
            file_output = gr.File(label="ğŸ“¥ ç»“æœä¸‹è½½", file_count="multiple")
            output_md = gr.Markdown(label="ğŸ“„ å®æ—¶é¢„è§ˆ")
    
    btn.click(fn=process_all_in_one, inputs=[api_input, input_box, mode_radio], outputs=[output_md, file_output])
    
    def clear():
        for f in os.listdir():
            if f.startswith(("temp_", "video_", "cache_")) or f.endswith((".mp3", ".txt", ".m4a")):
                try: os.remove(f)
                except: pass
        return "âœ¨ ç¼“å­˜å·²æ¸…ç©ºï¼Œå¯ä»¥å¼€å§‹å¤„ç†æ–°æ–‡ä»¶äº†ã€‚", None
    clear_btn.click(fn=clear, outputs=[output_md, file_output])

if __name__ == "__main__":
    demo.launch(share=True, debug=True)
