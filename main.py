import os, whisper, yt_dlp, shutil, time
from openai import OpenAI
import gradio as gr

def process_video_batch(api_key, video_urls_str, harvest_mode):
    """æ‰¹é‡å¤„ç†é€»è¾‘ï¼šå¾ªç¯æ¯ä¸€ä¸ªé“¾æ¥"""
    final_key = api_key if api_key and "sk-" in api_key else "sk-placeholder"
    
    # 1. æ‹†åˆ†é“¾æ¥
    urls = [u.strip() for u in video_urls_str.split('\n') if u.strip()]
    
    if "placeholder" in final_key:
        yield "âŒ é”™è¯¯ï¼šè¯·åœ¨ç•Œé¢è¾“å…¥æœ‰æ•ˆçš„ API_KEY", None
        return
    if not urls:
        yield "âŒ é”™è¯¯ï¼šè¯·è¾“å…¥è‡³å°‘ä¸€ä¸ªé“¾æ¥ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰", None
        return

    client = OpenAI(api_key=final_key, base_url="https://dashscope.aliyuncs.com/compatible-mode/v1")
    all_summary_report = ""
    all_segmented_files = []

    for idx, url in enumerate(urls):
        header = f"### ğŸ“º æ­£åœ¨å¤„ç† ({idx+1}/{len(urls)}): {url}\n"
        yield all_summary_report + header + "æ­£åœ¨å¯åŠ¨...", all_segmented_files
        
        try:
            # 2. æ–‡ä»¶ååˆå§‹åŒ–
            audio_file = f"temp_audio_{idx}.m4a"
            txt_cache = f"raw_{idx}.txt"
            
            # --- A. è·å–éŸ³é¢‘ ---
            if not os.path.exists(audio_file):
                yield all_summary_report + header + "ğŸ“¥ æ­£åœ¨æŠ“å–éŸ³é¢‘...", all_segmented_files
                audio_opts = {
                    'format': 'm4a/bestaudio/best',
                    'outtmpl': f'temp_audio_{idx}.%(ext)s',
                    'postprocessors': [{'key': 'FFmpegExtractAudio','preferredcodec': 'm4a'}],
                    'quiet': True
                }
                with yt_dlp.YoutubeDL(audio_opts) as ydl:
                    ydl.download([url])

            # --- B. è¯­éŸ³è¯†åˆ« ---
            if os.path.exists(txt_cache):
                with open(txt_cache, "r", encoding="utf-8") as f:
                    content_text = f.read()
            else:
                yield all_summary_report + header + "ğŸ™ï¸ Whisper å¬å†™ä¸­...", all_segmented_files
                import torch
                device = "cuda" if torch.cuda.is_available() else "cpu"
                model = whisper.load_model("base", device=device) 
                result = model.transcribe(audio_file)
                content_text = result['text']
                with open(txt_cache, "w", encoding="utf-8") as f:
                    f.write(content_text)

            # --- C. åˆ†ä¸åŒæ¨¡å¼è¿›è¡Œ AI å¤„ç† ---
            if harvest_mode == "é€»è¾‘å¤§çº²æ¨¡å¼":
                seg_file = f"video_{idx+1}_åˆ†æ®µåŸç¨¿.txt"
                yield all_summary_report + header + "ğŸ“‘ æ­£åœ¨åŸæ„åˆ†æ®µ...", all_segmented_files
                
                # æ­¥éª¤ 1: åˆ†æ®µ
                split_prompt = f"ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„é€Ÿè®°å‘˜ã€‚è¯·å¯¹ä»¥ä¸‹æ–‡ç¨¿è¿›è¡Œã€ä»…åˆ†æ®µä¸åŠ æ ‡ç‚¹ã€‘å¤„ç†ï¼Œä¸¥ç¦åˆ å‡ã€æ”¹åŠ¨æˆ–æ¶¦è‰²åŸæ–‡ä»»ä½•è¯è¯­ï¼š\n\n{content_text}"
                split_res = client.chat.completions.create(model="qwen-turbo", messages=[{"role": "user", "content": split_prompt}])
                segmented_text = split_res.choices[0].message.content
                with open(seg_file, "w", encoding="utf-8") as f:
                    f.write(segmented_text)
                all_segmented_files.append(seg_file)

                # æ­¥éª¤ 2: å¤§çº²
                yield all_summary_report + header + "âœï¸ æ­£åœ¨æç‚¼å¤§çº²...", all_segmented_files
                map_prompt = f"ä½ æ˜¯ä¸€ä½é¡¶çº§çš„é€»è¾‘åˆ†æå¸ˆã€‚è¯·åŸºäºä»¥ä¸‹åˆ†æ®µæ–‡ç¨¿æå–å¤§çº²å’Œ mermaid mindmap ä»£ç ã€‚è¦æ±‚ï¼šä¸¥æ ¼ä¿ç•™æ ¸å¿ƒè®ºç‚¹ï¼Œç”¨ã€Œã€åŒ…è£¹é‡‘å¥ã€‚\n\næ–‡ç¨¿å†…å®¹ï¼š\n{segmented_text}"
                map_res = client.chat.completions.create(model="qwen-plus", messages=[{"role": "user", "content": map_prompt}])
                map_content = map_res.choices[0].message.content
                all_summary_report += f"\n---\n{header}\n{map_content}\n"

            else:  # ç¿»è¯‘æ¨¡å¼
                trans_file = f"video_{idx+1}_ä¸­è‹±å¯¹ç…§ç¿»è¯‘.txt"
                yield all_summary_report + header + "ğŸŒ æ­£åœ¨è¿›è¡Œé€æ®µä¸­è‹±å¯¹ç…§...", all_segmented_files
                
                # ä½¿ç”¨ä½ æä¾›çš„ä¼˜è´¨ç¿»è¯‘ Prompt
                translate_prompt = f"""ä»»åŠ¡ï¼š æ–‡æœ¬é€æ®µåˆ†æ®µä¸ç¿»è¯‘å¯¹ç…§è¦æ±‚ï¼š
                1. é€»è¾‘åˆ†æ®µï¼š æ ¹æ®æ–‡æœ¬å†…å®¹çš„å†…åœ¨é€»è¾‘å¯¹åŸå§‹æ–‡æœ¬è¿›è¡Œåˆ†æ®µã€‚
                2. é€æ®µå¯¹ç…§æ ¼å¼ï¼š è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼äº¤æ›¿è¾“å‡ºï¼š
                [æ®µè½åŸæ–‡]
                [æ®µè½ç¿»è¯‘]
                ---
                3. ä¸¥ç¦æ”¹å†™æˆ–ç¼©å‡ï¼š åŸæ–‡éƒ¨åˆ†å¿…é¡»ä¿æŒä¸è¾“å…¥å®Œå…¨ä¸€è‡´ï¼Œä¸å¾—ä¿®æ”¹ã€æ€»ç»“æˆ–é—æ¼ä»»ä½•å•è¯ã€‚
                4. ç²¾å‡†ç¿»è¯‘ï¼š ç¿»è¯‘éœ€ç¡®ä¿è¯­æ„ç²¾å‡†ï¼Œä¸”ä¸ä¸Šæ–¹çš„åŸæ–‡æ®µè½ä¸¥æ ¼å¯¹åº”ã€‚
                5. ç¦æ­¢é¢å¤–å†…å®¹ï¼š ä¸è¦å†™æ‘˜è¦ã€ä¸è¦æ·»åŠ è¯„è®ºã€ä¸è¦æ”¹å˜æ–‡æœ¬é¡ºåºã€‚
                
                å¾…å¤„ç†æ–‡æœ¬ï¼š
                {content_text}"""
                
                trans_res = client.chat.completions.create(model="qwen-plus", messages=[{"role": "user", "content": translate_prompt}])
                translated_content = trans_res.choices[0].message.content
                
                with open(trans_file, "w", encoding="utf-8") as f:
                    f.write(translated_content)
                all_segmented_files.append(trans_file)
                all_summary_report += f"\n---\n{header}\nâœ… ç¿»è¯‘å®Œæˆï¼Œè¯·åœ¨ä¸‹æ–¹ä¸‹è½½æ–‡ä»¶æŸ¥çœ‹è¯¦æƒ…ã€‚\n"

            yield all_summary_report, all_segmented_files

        except Exception as e:
            error_msg = f"\nâŒ è§†é¢‘ {idx+1} è¿è¡ŒæŠ¥é”™: {str(e)}\n"
            all_summary_report += error_msg
            yield all_summary_report, all_segmented_files

    yield all_summary_report + "\n\nâœ… æ‰€æœ‰ä»»åŠ¡å¤„ç†å®Œæˆï¼", all_segmented_files

# --- Gradio ç•Œé¢è®¾è®¡ ---
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("# ğŸ“ å­¦æœ¯è§†é¢‘å¤šåŠŸèƒ½æ”¶å‰²æœº (ADHDå‹å¥½/ä¸é˜‰å‰²ç‰ˆ)")
    with gr.Row():
        with gr.Column(scale=1):
            api_input = gr.Textbox(label="API KEY", type="password")
            url_input = gr.Textbox(label="è§†é¢‘é“¾æ¥ (æ¯è¡Œä¸€ä¸ª)", lines=5, placeholder="ç²˜è´´å¤šä¸ªé“¾æ¥ï¼Œä¸€è¡Œä¸€ä¸ª...")
            # --- æ¨¡å¼åˆ‡æ¢æŒ‰é’® ---
            mode_radio = gr.Radio(
                choices=["é€»è¾‘å¤§çº²æ¨¡å¼", "é€æ®µç¿»è¯‘å¯¹ç…§"], 
                value="é€»è¾‘å¤§çº²æ¨¡å¼", 
                label="é€‰æ‹©æ”¶å‰²æ¨¡å¼"
            )
            btn = gr.Button("ğŸš€ å¼€å§‹æ”¶å‰²", variant="primary")
            clear_btn = gr.Button("ğŸ§¹ æ¸…ç©ºæ‰€æœ‰ç¼“å­˜")
        with gr.Column(scale=2):
            file_output = gr.File(label="ğŸ“¥ ä¸‹è½½ç”Ÿæˆçš„æ–‡ä»¶", file_count="multiple")
            output_md = gr.Markdown(label="ğŸ“„ æ±‡æ€»çŠ¶æ€æŠ¥å‘Š")
    
    # ç»‘å®šç‚¹å‡»äº‹ä»¶ï¼Œæ³¨æ„å¢åŠ äº† mode_radio ä½œä¸ºè¾“å…¥
    btn.click(fn=process_video_batch, inputs=[api_input, url_input, mode_radio], outputs=[output_md, file_output])
    
    def clear_all():
        files_to_delete = [f for f in os.listdir() if f.endswith((".m4a", ".txt", ".md"))]
        for f in files_to_delete: os.remove(f)
        return "âœ¨ æ‰€æœ‰ç¼“å­˜æ–‡ä»¶å·²æ¸…ç†ã€‚", None
    clear_btn.click(fn=clear_all, outputs=[output_md, file_output])

if __name__ == "__main__":
    demo.launch(share=True, debug=True)
