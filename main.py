import os, whisper, yt_dlp, shutil
from openai import OpenAI
import gradio as gr

# --- å¤–éƒ¨æ¥å£åŒº ---
API_KEY = "sk-placeholder"

def process_video(api_key, video_url):
    """Gradio è°ƒç”¨çš„æ ¸å¿ƒé€»è¾‘å‡½æ•°"""
    final_key = api_key if api_key and "sk-" in api_key else API_KEY
    
    if "placeholder" in final_key:
        yield "âŒ é”™è¯¯ï¼šè¯·åœ¨ç•Œé¢è¾“å…¥æœ‰æ•ˆçš„ API_KEY", None
        return

    try:
        # --- 1. éŸ³é¢‘è·å– ---
        audio_file = "temp_audio.m4a"
        if not os.path.exists(audio_file):
            yield "ğŸ“¥ æ­£åœ¨ä»æºç«™æŠ“å–éŸ³é¢‘...", None
            audio_opts = {
                'format': 'm4a/bestaudio/best',
                'outtmpl': 'temp_audio.%(ext)s',
                'postprocessors': [{'key': 'FFmpegExtractAudio','preferredcodec': 'm4a'}],
                'quiet': True
            }
            with yt_dlp.YoutubeDL(audio_opts) as ydl:
                ydl.download([video_url])

        # --- 2. è¯­éŸ³è¯†åˆ« (ç¼“å­˜) ---
        txt_cache = "raw_transcript.txt"
        if os.path.exists(txt_cache):
            with open(txt_cache, "r", encoding="utf-8") as f:
                content_text = f.read()
        else:
            yield "ğŸ™ï¸ Whisper æ­£åœ¨æ‹¼å‘½å¬å†™...", None
            import torch
            device = "cuda" if torch.cuda.is_available() else "cpu"
            model = whisper.load_model("base", device=device) 
            result = model.transcribe(audio_file)
            content_text = result['text']
            with open(txt_cache, "w", encoding="utf-8") as f:
                f.write(content_text)
        
        # --- 3. æ ¸å¿ƒæ”¹è¿›ï¼šåŸæ„åˆ†æ®µ (ä½¿ç”¨ Turbo æ¨¡å‹è§„é¿å®¡æ ¸ä¸”ä¿çœŸ) ---
        yield "ğŸ“‘ æ­£åœ¨è¿›è¡Œã€åŸæ„åˆ†æ®µã€‘(ä¸åˆ å‡åŸæ–‡)...", None
        client = OpenAI(api_key=final_key, base_url="https://dashscope.aliyuncs.com/compatible-mode/v1")
        
        split_prompt = f"""
        ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„é€Ÿè®°å‘˜ã€‚è¯·å¯¹ä»¥ä¸‹æ–‡ç¨¿è¿›è¡Œã€ä»…åˆ†æ®µä¸åŠ æ ‡ç‚¹ã€‘å¤„ç†ï¼š
        1. ä¸¥ç¦åˆ å‡ã€æ”¹åŠ¨æˆ–æ¶¦è‰²åŸæ–‡ä»»ä½•è¯è¯­ã€‚
        2. ä»…æ ¹æ®è¯­ä¹‰è¿›è¡Œè‡ªç„¶æ®µè½åˆ‡åˆ†å¹¶è¡¥å……æ ‡ç‚¹ã€‚
        3. è¿™æ˜¯ä¸€ä¸ªå…³äºäººæ–‡/å¿ƒç†å­¦çš„å­¦æœ¯æ¢è®¨ï¼Œè¯·ä¿æŒå…¶åŸå§‹è¡¨è¿°ã€‚
        
        å¾…å¤„ç†å†…å®¹ï¼š
        {content_text}
        """
        split_res = client.chat.completions.create(model="qwen-turbo", messages=[{"role": "user", "content": split_prompt}])
        segmented_text = split_res.choices[0].message.content
        
        # ä¿å­˜åˆ†æ®µåŸç¨¿æ–‡ä»¶
        seg_file = "1_åˆ†æ®µåŸç¨¿.txt"
        with open(seg_file, "w", encoding="utf-8") as f:
            f.write(segmented_text)

        # --- 4. é€»è¾‘æ€»ç»“ + æ€ç»´å¯¼å›¾ ---
        yield "âœï¸ æ­£åœ¨åŸºäºåˆ†æ®µç¨¿ç”Ÿæˆå¤§çº² & æ€ç»´å¯¼å›¾...", seg_file
        map_prompt = f"""
        ä½ æ˜¯ä¸€ä½é¡¶çº§çš„é€»è¾‘åˆ†æå¸ˆã€‚è¯·åŸºäºä»¥ä¸‹åˆ†æ®µæ–‡ç¨¿æå–å¤§çº²ï¼š
        - # ä¸€çº§æ ‡é¢˜ï¼šä¸»é¢˜
        - ## äºŒçº§æ ‡é¢˜ï¼šæ ¸å¿ƒé€»è¾‘æ¿å—
        - ### ä¸‰çº§æ ‡é¢˜ï¼šå…·ä½“è®ºç‚¹/å­è§‚ç‚¹
        - - åˆ—è¡¨é¡¹ï¼šç”¨ã€Œã€åŒ…è£¹çš„åŸæ–‡é‡‘å¥ã€‚
        - æœ€åé™„å¸¦ä¸€æ®µ ```mermaid mindmap ä»£ç ã€‚
        
        æ–‡ç¨¿å†…å®¹ï¼š
        {segmented_text}
        """
        map_res = client.chat.completions.create(model="qwen-plus", messages=[{"role": "user", "content": map_prompt}])
        map_content = map_res.choices[0].message.content
        
        yield map_content, seg_file

    except Exception as e:
        yield f"âŒ è¿è¡ŒæŠ¥é”™: {str(e)}", None

# --- Gradio ç•Œé¢è®¾è®¡ ---
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("# ğŸ“ å­¦æœ¯è§†é¢‘æ”¶å‰²æœº (åŸæ„ä¿ç•™+æ€ç»´å¯¼å›¾ç‰ˆ)")
    with gr.Row():
        with gr.Column(scale=1):
            api_input = gr.Textbox(label="API KEY", type="password")
            url_input = gr.Textbox(label="è§†é¢‘/æ’­å®¢é“¾æ¥")
            btn = gr.Button("ğŸ”¥ å¼€å§‹æ”¶å‰²", variant="primary")
            clear_btn = gr.Button("ğŸ§¹ æ¸…ç©ºç¼“å­˜")
        with gr.Column(scale=2):
            file_output = gr.File(label="ç¬¬ä¸€æ­¥ï¼šä¸‹è½½åˆ†æ®µåŸç¨¿")
            output_md = gr.Markdown(label="ç¬¬äºŒæ­¥ï¼šç”Ÿæˆçš„æ·±åº¦æ€»ç»“")
    
    btn.click(fn=process_video, inputs=[api_input, url_input], outputs=[output_md, file_output])
    
    def clear_cache():
        for f in ["temp_audio.m4a", "raw_transcript.txt", "1_åˆ†æ®µåŸç¨¿.txt"]:
            if os.path.exists(f): os.remove(f)
        return "âœ¨ ç¼“å­˜å·²æ¸…ç†ã€‚", None
    clear_btn.click(fn=clear_cache, outputs=[output_md, file_output])

if __name__ == "__main__":
    demo.launch(share=True, debug=True)
