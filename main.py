import os, whisper, yt_dlp, shutil
from openai import OpenAI
from google.colab import files
import markdown
from IPython.display import display, HTML

# --- å¤–éƒ¨æ¥å£åŒº ---
API_KEY = "sk-placeholder"
VIDEO_URL = "url-placeholder"

def run_podcast_tool():
    if "placeholder" in API_KEY or "placeholder" in VIDEO_URL:
        print("âŒ é”™è¯¯ï¼šè¯·å…ˆè®¾ç½® API_KEY å’Œ VIDEO_URL")
        return

    try:
        content_text = ""
        
        # 1. å°è¯•æé€ŸæŠ“å–å­—å¹•
        print(f"ğŸ” æ­£åœ¨å°è¯•ä»æºç«™æå–ç°æˆå­—å¹•...")
        ydl_opts_subs = {
            'skip_download': True,
            'writesubtitles': True,
            'writeautomaticsub': True,
            'subtitleslangs': ['zh-Hans', 'zh-CN', 'zh', 'en'],
            'outtmpl': 'subtitle_file',
            'quiet': True
        }
        
        try:
            with yt_dlp.YoutubeDL(ydl_opts_subs) as ydl:
                info = ydl.extract_info(VIDEO_URL, download=True)
                if 'requested_subtitles' in info and info['requested_subtitles']:
                    print("âœ… æˆåŠŸè·å–åœ¨çº¿å­—å¹•ï¼æ­£åœ¨é—ªç”µæå–...")
                else:
                    print("â„¹ï¸ æœªæ£€æµ‹åˆ°å¤–æŒ‚å­—å¹•ã€‚")
        except:
            pass

        # 2. è¯­éŸ³è¯†åˆ«ä¿åº• (é…åˆ GPU æé€Ÿ)
        if not content_text:
            print(f"ğŸ“¥ æ­£åœ¨è·å–éŸ³é¢‘å¹¶å¯åŠ¨è¯†åˆ«æµç¨‹ (1å°æ—¶è§†é¢‘é¢„è®¡ 5-10 åˆ†é’Ÿ)...")
            audio_opts = {
                'format': 'm4a/bestaudio/best',
                'outtmpl': 'temp_audio.%(ext)s',
                'postprocessors': [{'key': 'FFmpegExtractAudio','preferredcodec': 'm4a'}],
                'quiet': True
            }
            with yt_dlp.YoutubeDL(audio_opts) as ydl:
                ydl.download([VIDEO_URL])
            
            # ä½¿ç”¨ base æ¨¡å‹ï¼Œè‡ªåŠ¨æ£€æµ‹ GPU
            import torch
            device = "cuda" if torch.cuda.is_available() else "cpu"
            model = whisper.load_model("base", device=device) 
            result = model.transcribe("temp_audio.m4a")
            content_text = result['text']
        
        # 3. è¯­ä¹‰æ•´å½¢
        print("ğŸ” æ­£åœ¨è¿›è¡Œæ–‡æœ¬æ•´å½¢æ‰‹æœ¯ (è¯­ä¹‰çº é”™ & æ ‡ç‚¹è¿˜åŸ)...")
        client = OpenAI(api_key=API_KEY, base_url="https://dashscope.aliyuncs.com/compatible-mode/v1")
        
        correction_prompt = f"""
        ä½ æ˜¯ä¸€ä½ç²¾é€šä¸­æ–‡è¯­å¢ƒçš„èµ„æ·±ç¼–è¾‘ã€‚è¯·å¯¹ä»¥ä¸‹è¯­éŸ³ç¨¿è¿›è¡Œâ€œæ·±åº¦é‡å¡‘â€ï¼š
        1. ã€åŠ æ ‡ç‚¹ä¸æ–­å¥ã€‘ï¼šæ ¹æ®è¯­ä¹‰æ·»åŠ æ ‡ç‚¹ã€‚ä¸¥ç¦å‡ºç°è¶…è¿‡15å­—æ²¡æœ‰æ ‡ç‚¹çš„é•¿å¥ï¼Œç¡®ä¿èŠ‚å¥æ„Ÿã€‚
        2. ã€å…¨èƒ½çº é”™ã€‘ï¼šç»“åˆä¸Šä¸‹æ–‡ï¼Œè‡ªåŠ¨ä¿®æ­£è°éŸ³é”™è¯¯ï¼ˆå¦‚ï¼šç¬‘èˆ¹->å“®å–˜, å®Œæ™’->å®Œèµ›, é‚»æ°”->çµæ€§, å¢¨ç”Ÿ->é»˜ç”Ÿï¼‰ã€‚
        3. ã€å»é™¤å£è¯­èµ˜è¯ã€‘ï¼šè¿‡æ»¤â€œé‚£ä¸ªã€å°±æ˜¯ã€ç„¶åã€å‘ƒã€æˆ‘çš„è¯ã€å¯¹å§â€ç­‰å¡«å……è¯ã€‚
        4. ã€åˆ†æ®µã€‘ï¼šæ¯æ®µåªèšç„¦ä¸€ä¸ªæ ¸å¿ƒè¯­ä¹‰ç‚¹ã€‚
        
        å†…å®¹å¦‚ä¸‹ï¼š
        {content_text}
        """
        
        corr_res = client.chat.completions.create(model="qwen-plus", messages=[{"role": "user", "content": correction_prompt}])
        corrected_text = corr_res.choices[0].message.content

        # 4. æ·±åº¦é€»è¾‘å¤§çº²æå–
        print("âœï¸ æ­£åœ¨ç”Ÿæˆå¸¦é‡‘å¥çš„æ·±åº¦é€»è¾‘å¤§çº²...")
        map_prompt = f"""
        ä½ æ˜¯ä¸€ä½é¡¶çº§çš„é€»è¾‘åˆ†æå¸ˆã€‚è¯·åŸºäºä»¥ä¸‹ç²¾æ’æ–‡ç¨¿æå–å¤§çº²ï¼š
        - # ä¸€çº§æ ‡é¢˜ï¼šä¸»é¢˜
        - ## äºŒçº§æ ‡é¢˜ï¼šæ ¸å¿ƒé€»è¾‘æ¿å—
        - ### ä¸‰çº§æ ‡é¢˜ï¼šå…·ä½“è®ºç‚¹/å­è§‚ç‚¹
        - - åˆ—è¡¨é¡¹ï¼šç”¨ã€Œã€åŒ…è£¹çš„åŸæ–‡æ ¸å¿ƒé‡‘å¥ã€‚
        
        æ–‡ç¨¿å†…å®¹ï¼š
        {corrected_text}
        """
        map_res = client.chat.completions.create(model="qwen-plus", messages=[{"role": "user", "content": map_prompt}])
        map_content = map_res.choices[0].message.content

        # 5. ä¸‹è½½ã€é¢„è§ˆä¸ç½‘ç›˜å¤‡ä»½
        filename1 = "1_ç²¾æ’æ–‡ç¨¿.txt"
        filename2 = "2_æ·±åº¦é€»è¾‘å¤§çº².md"
        
        with open(filename1, "w", encoding="utf-8") as f: f.write(corrected_text)
        with open(filename2, "w", encoding="utf-8") as f: f.write(map_content)
        
        # è‡ªåŠ¨è§¦å‘æµè§ˆå™¨ä¸‹è½½
        files.download(filename1)
        files.download(filename2)

        # æ ¸å¿ƒï¼šGoogle Drive è‡ªåŠ¨å¤‡ä»½é€»è¾‘
        drive_path = "/content/drive/MyDrive/AI_Notes/"
        if os.path.exists("/content/drive"):
            if not os.path.exists(drive_path):
                os.makedirs(drive_path)
            shutil.copy(filename1, os.path.join(drive_path, filename1))
            shutil.copy(filename2, os.path.join(drive_path, filename2))
            print(f"ğŸ’¾ å¤‡ä»½æˆåŠŸï¼æ–‡ä»¶å·²å­˜å…¥ Google Drive: {drive_path}")
        else:
            print("ğŸ’¡ æç¤ºï¼šæœªæŒ‚è½½ Google Driveï¼Œæ–‡ä»¶ä»…ä¿å­˜åœ¨ä¸´æ—¶ä¼šè¯ä¸­ã€‚")

        print("\n--- ğŸ“ å®æ—¶é¢„è§ˆ ---")
        display(HTML(f"<div style='background:#f9f9f9; padding:20px; border-radius:12px; border:1px solid #ddd; line-height:1.8;'>{markdown.markdown(map_content)}</div>"))

    except Exception as e:
        print(f"âŒ è¿è¡ŒæŠ¥é”™: {e}")

if __name__ == "__main__":
    run_podcast_tool()


# --- Gradio ç•Œé¢è®¾è®¡ ---
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("# ğŸ“ å­¦æœ¯è§†é¢‘/æ’­å®¢æ·±åº¦æ”¶å‰²æœº")
    with gr.Row():
        with gr.Column():
            api_input = gr.Textbox(label="DeepSeek API KEY", placeholder="sk-...", type="password")
            url_input = gr.Textbox(label="è§†é¢‘/æ’­å®¢é“¾æ¥", placeholder="æ”¯æŒ Bç«™ã€YouTubeã€å°å®‡å®™...")
            btn = gr.Button("ğŸ”¥ å¼€å§‹æ”¶å‰² (å»ºè®®å¼€å¯ T4 GPU)", variant="primary")
        with gr.Column():
            output = gr.Markdown(label="ç”Ÿæˆçš„æ·±åº¦å¤§çº²")
    
    btn.click(fn=process_video, inputs=[api_input, url_input], outputs=output)

if __name__ == "__main__":
    # share=True ä¼šç”Ÿæˆä¸€ä¸ªå…¬ç½‘é“¾æ¥ï¼Œä½ å¯ä»¥å‘ç»™æ‰‹æœºæˆ–è€…æœ‹å‹ç”¨
    demo.launch(share=True, debug=True)
