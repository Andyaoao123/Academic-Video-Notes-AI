import os, whisper, yt_dlp, shutil
from openai import OpenAI
from google.colab import files
import markdown
import gradio as gr
from IPython.display import display, HTML

# --- å¤–éƒ¨æ¥å£åŒº ---
API_KEY = "sk-placeholder"
VIDEO_URL = "url-placeholder"

def process_video(api_key, video_url):
    """Gradio è°ƒç”¨çš„æ ¸å¿ƒé€»è¾‘å‡½æ•°"""
    final_key = api_key if api_key and "sk-" in api_key else API_KEY
    
    if "placeholder" in final_key:
        yield "âŒ é”™è¯¯ï¼šè¯·åœ¨ç•Œé¢è¾“å…¥æœ‰æ•ˆçš„ API_KEY"
        return
    if not video_url:
        yield "âŒ é”™è¯¯ï¼šè¯·è¾“å…¥è§†é¢‘æˆ–æ’­å®¢é“¾æ¥"
        return

    try:
        # --- 1. éŸ³é¢‘è·å– (æ–­ç‚¹ç»­ä¼ ) ---
        audio_file = "temp_audio.m4a"
        if os.path.exists(audio_file):
            yield "ğŸ“ æ£€æµ‹åˆ°æœ¬åœ°å·²å­˜åœ¨éŸ³é¢‘ï¼Œè·³è¿‡ä¸‹è½½æ­¥éª¤..."
        else:
            yield "ğŸ“¥ æ­£åœ¨ä»æºç«™æŠ“å–éŸ³é¢‘ (è¿™å¯èƒ½éœ€è¦ 1-2 åˆ†é’Ÿ)..."
            audio_opts = {
                'format': 'm4a/bestaudio/best',
                'outtmpl': 'temp_audio.%(ext)s',
                'postprocessors': [{'key': 'FFmpegExtractAudio','preferredcodec': 'm4a'}],
                'quiet': True
            }
            with yt_dlp.YoutubeDL(audio_opts) as ydl:
                ydl.download([video_url])

        # --- 2. è¯­éŸ³è¯†åˆ« (ç¼“å­˜é€»è¾‘) ---
        txt_cache = "raw_transcript.txt"
        if os.path.exists(txt_cache):
            yield "ğŸ“„ æ£€æµ‹åˆ°å·²å­˜åœ¨è¯†åˆ«æ–‡æœ¬ï¼Œè·³è¿‡å¬å†™ï¼Œè¿›å…¥ AI åˆ†æ..."
            with open(txt_cache, "r", encoding="utf-8") as f:
                content_text = f.read()
        else:
            yield "ğŸ™ï¸ Whisper æ­£åœ¨æ‹¼å‘½å¬å†™ (å¼€å¯ GPU çº¦éœ€ 5-10 åˆ†é’Ÿ)..."
            import torch
            device = "cuda" if torch.cuda.is_available() else "cpu"
            model = whisper.load_model("base", device=device) 
            result = model.transcribe(audio_file)
            content_text = result['text']
            with open(txt_cache, "w", encoding="utf-8") as f:
                f.write(content_text)
        
        # --- 3. è¯­ä¹‰æ•´å½¢ ---
        yield "ğŸ” æ­£åœ¨è¿›è¡Œæ–‡æœ¬æ•´å½¢æ‰‹æœ¯..."
        client = OpenAI(api_key=final_key, base_url="https://dashscope.aliyuncs.com/compatible-mode/v1")
        
        correction_prompt = f"è¯·å¯¹ä»¥ä¸‹è¯­éŸ³ç¨¿è¿›è¡Œæ·±åº¦é‡å¡‘ï¼ˆåŠ æ ‡ç‚¹ã€åˆ†æ®µã€çº é”™ã€å»å£è¯­ï¼‰ï¼š\n{content_text}"
        corr_res = client.chat.completions.create(model="qwen-plus", messages=[{"role": "user", "content": correction_prompt}])
        corrected_text = corr_res.choices[0].message.content

        # --- 4. æ·±åº¦é€»è¾‘å¤§çº² + æ€ç»´å¯¼å›¾æå– ---
        yield "âœï¸ æ­£åœ¨ç”Ÿæˆå¸¦é‡‘å¥çš„å¤§çº² & æ€ç»´å¯¼å›¾ä»£ç ..."
        map_prompt = f"""
        ä½ æ˜¯ä¸€ä½é¡¶çº§çš„é€»è¾‘åˆ†æå¸ˆã€‚è¯·åŸºäºä»¥ä¸‹ç²¾æ’æ–‡ç¨¿è¿›è¡Œæ·±åº¦æ€»ç»“ï¼š
        
        1. ã€æ–‡å­—å¤§çº²ã€‘ï¼š
           - # ä¸€çº§æ ‡é¢˜ï¼šä¸»é¢˜
           - ## äºŒçº§æ ‡é¢˜ï¼šæ ¸å¿ƒé€»è¾‘æ¿å—
           - ### ä¸‰çº§æ ‡é¢˜ï¼šå…·ä½“è®ºç‚¹/å­è§‚ç‚¹
           - - åˆ—è¡¨é¡¹ï¼šç”¨ã€Œã€åŒ…è£¹çš„åŸæ–‡æ ¸å¿ƒé‡‘å¥ã€‚
        
        2. ã€Mermaid æ€ç»´å¯¼å›¾ä»£ç ã€‘ï¼š
           åœ¨æœ€åç”Ÿæˆä¸€æ®µä»£ç ï¼Œå¿…é¡»ä»¥ ```mermaid å¼€å¤´ï¼Œä½¿ç”¨ mindmap è¯­æ³•ï¼Œroot((ä¸»é¢˜)) ç»“æ„ã€‚
        
        æ–‡ç¨¿å†…å®¹ï¼š
        {corrected_text}
        """
        map_res = client.chat.completions.create(model="qwen-plus", messages=[{"role": "user", "content": map_prompt}])
        map_content = map_res.choices[0].message.content

        # --- 5. ä¿å­˜ ---
        filename = "æ·±åº¦é€»è¾‘æ€»ç»“.md"
        with open(filename, "w", encoding="utf-8") as f:
            f.write(map_content)
        
        yield map_content

    except Exception as e:
        yield f"âŒ è¿è¡ŒæŠ¥é”™: {str(e)}"

# --- Gradio ç•Œé¢è®¾è®¡ ---
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("# ğŸ“ å­¦æœ¯è§†é¢‘/æ’­å®¢æ·±åº¦æ”¶å‰²æœº (æ€ç»´å¯¼å›¾ç‰ˆ)")
    with gr.Row():
        with gr.Column():
            api_input = gr.Textbox(label="API KEY", type="password")
            url_input = gr.Textbox(label="è§†é¢‘é“¾æ¥")
            with gr.Row():
                btn = gr.Button("ğŸ”¥ å¼€å§‹æ”¶å‰²", variant="primary")
                clear_btn = gr.Button("ğŸ§¹ æ¸…ç©ºç¼“å­˜")
        with gr.Column():
            output = gr.Markdown(label="ç”Ÿæˆçš„æ·±åº¦å¤§çº²")
    
    btn.click(fn=process_video, inputs=[api_input, url_input], outputs=output)
    
    def clear_cache():
        for f in ["temp_audio.m4a", "raw_transcript.txt"]:
            if os.path.exists(f): os.remove(f)
        return "âœ¨ ç¼“å­˜å·²æ¸…ç†ã€‚"
    clear_btn.click(fn=clear_cache, outputs=output)

if __name__ == "__main__":
    demo.launch(share=True, debug=True)
