import os, whisper, yt_dlp, shutil
from openai import OpenAI
from google.colab import files
import markdown
import gradio as gr
from IPython.display import display, HTML

# --- å¤–éƒ¨æ¥å£åŒº ---
API_KEY = "sk-placeholder"
VIDEO_URL = "url-placeholder"

def process_video(api_key, video_url):
    """Gradio è°ƒç”¨çš„æ ¸å¿ƒé€»è¾‘å‡½æ•°"""
    # ä¼˜å…ˆä½¿ç”¨ç•Œé¢è¾“å…¥çš„ KEY
    final_key = api_key if api_key and "sk-" in api_key else API_KEY
    
    if "placeholder" in final_key:
        yield "âŒ é”™è¯¯ï¼šè¯·åœ¨ç•Œé¢è¾“å…¥æœ‰æ•ˆçš„ API_KEY"
        return
    if not video_url:
        yield "âŒ é”™è¯¯ï¼šè¯·è¾“å…¥è§†é¢‘æˆ–æ’­å®¢é“¾æ¥"
        return

    try:
        # --- 1. éŸ³é¢‘è·å– (æ–­ç‚¹ç»­ä¼ é€»è¾‘) ---
        audio_file = "temp_audio.m4a"
        if os.path.exists(audio_file):
            yield "ğŸ“ æ£€æµ‹åˆ°æœ¬åœ°å·²å­˜åœ¨éŸ³é¢‘ï¼Œè·³è¿‡ä¸‹è½½æ­¥éª¤..."
        else:
            yield "ğŸ“¥ æ­£åœ¨ä»æºç«™æŠ“å–éŸ³é¢‘ (è¿™å¯èƒ½éœ€è¦ 1-2 åˆ†é’Ÿ)..."
            audio_opts = {
                'format': 'm4a/bestaudio/best',
                'outtmpl': 'temp_audio.%(ext)s',
                'postprocessors': [{'key': 'FFmpegExtractAudio','preferredcodec': 'm4a'}],
                'quiet': True
            }
            with yt_dlp.YoutubeDL(audio_opts) as ydl:
                ydl.download([video_url])

        # --- 2. è¯­éŸ³è¯†åˆ« (ç¼“å­˜é€»è¾‘) ---
        txt_cache = "raw_transcript.txt"
        if os.path.exists(txt_cache):
            yield "ğŸ“„ æ£€æµ‹åˆ°å·²å­˜åœ¨è¯†åˆ«æ–‡æœ¬ï¼Œè·³è¿‡ Whisper å¬å†™ï¼Œç›´æ¥è¿›å…¥ AI å¤„ç†..."
            with open(txt_cache, "r", encoding="utf-8") as f:
                content_text = f.read()
        else:
            yield "ğŸ™ï¸ Whisper æ­£åœ¨æ‹¼å‘½å¬å†™ (1å°æ—¶è§†é¢‘çº¦éœ€ 5-10 åˆ†é’Ÿ)..."
            import torch
            device = "cuda" if torch.cuda.is_available() else "cpu"
            model = whisper.load_model("base", device=device) 
            result = model.transcribe(audio_file)
            content_text = result['text']
            # å†™å…¥ç¼“å­˜ï¼Œé˜²æ­¢ä¸‹æ¬¡å´©æºƒé‡æ¥
            with open(txt_cache, "w", encoding="utf-8") as f:
                f.write(content_text)
        
        # --- 3. è¯­ä¹‰æ•´å½¢ ---
        yield "ğŸ” æ­£åœ¨è¿›è¡Œæ–‡æœ¬æ•´å½¢æ‰‹æœ¯ (è¯­ä¹‰çº é”™ & æ ‡ç‚¹è¿˜åŸ)..."
        client = OpenAI(api_key=final_key, base_url="https://dashscope.aliyuncs.com/compatible-mode/v1")
        
        correction_prompt = f"""
        ä½ æ˜¯ä¸€ä½ç²¾é€šä¸­æ–‡è¯­å¢ƒçš„èµ„æ·±ç¼–è¾‘ã€‚è¯·å¯¹ä»¥ä¸‹è¯­éŸ³ç¨¿è¿›è¡Œâ€œæ·±åº¦é‡å¡‘â€ï¼š
        1. ã€åŠ æ ‡ç‚¹ä¸æ–­å¥ã€‘ï¼šæ ¹æ®è¯­ä¹‰æ·»åŠ æ ‡ç‚¹ã€‚ä¸¥ç¦å‡ºç°è¶…è¿‡15å­—æ²¡æœ‰æ ‡ç‚¹çš„é•¿å¥ã€‚
        2. ã€å…¨èƒ½çº é”™ã€‘ï¼šè‡ªåŠ¨ä¿®æ­£è°éŸ³é”™è¯¯ï¼ˆå¦‚ï¼šç¬‘èˆ¹->å“®å–˜, é‚»æ°”->çµæ€§ï¼‰ã€‚
        3. ã€å»é™¤å£è¯­èµ˜è¯ã€‘ï¼šè¿‡æ»¤â€œé‚£ä¸ªã€å°±æ˜¯ã€ç„¶åã€å‘ƒâ€ç­‰ã€‚
        4. ã€åˆ†æ®µã€‘ï¼šæ¯æ®µåªèšç„¦ä¸€ä¸ªæ ¸å¿ƒè¯­ä¹‰ç‚¹ã€‚
        
        å†…å®¹å¦‚ä¸‹ï¼š
        {content_text}
        """
        
        corr_res = client.chat.completions.create(model="qwen-plus", messages=[{"role": "user", "content": correction_prompt}])
        corrected_text = corr_res.choices[0].message.content

        # --- 4. æ·±åº¦é€»è¾‘å¤§çº²æå– ---
        yield "âœï¸ æ­£åœ¨ç”Ÿæˆå¸¦é‡‘å¥çš„æ·±åº¦é€»è¾‘å¤§çº²..."
        map_prompt = f"""
        ä½ æ˜¯ä¸€ä½é¡¶çº§çš„é€»è¾‘åˆ†æå¸ˆã€‚è¯·åŸºäºä»¥ä¸‹ç²¾æ’æ–‡ç¨¿æå–å¤§çº²ï¼š
        - # ä¸€çº§æ ‡é¢˜ï¼šä¸»é¢˜
        - ## äºŒçº§æ ‡é¢˜ï¼šæ ¸å¿ƒé€»è¾‘æ¿å—
        - ### ä¸‰çº§æ ‡é¢˜ï¼šå…·ä½“è®ºç‚¹/å­è§‚ç‚¹
        - - åˆ—è¡¨é¡¹ï¼šç”¨ã€Œã€åŒ…è£¹çš„åŸæ–‡æ ¸å¿ƒé‡‘å¥ã€‚
        
        æ–‡ç¨¿å†…å®¹ï¼š
        {corrected_text}
        """
        map_res = client.chat.completions.create(model="qwen-plus", messages=[{"role": "user", "content": map_prompt}])
        map_content = map_res.choices[0].message.content

        # --- 5. ä¿å­˜å¹¶å±•ç¤º ---
        filename = "æ·±åº¦é€»è¾‘å¤§çº².md"
        with open(filename, "w", encoding="utf-8") as f:
            f.write(map_content)
        
        yield map_content

    except Exception as e:
        yield f"âŒ è¿è¡ŒæŠ¥é”™: {str(e)}"

# --- Gradio ç•Œé¢è®¾è®¡ ---
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("# ğŸ“ å­¦æœ¯è§†é¢‘/æ’­å®¢æ·±åº¦æ”¶å‰²æœº (æ–­ç‚¹ç»­ä¼ ç‰ˆ)")
    with gr.Row():
        with gr.Column():
            api_input = gr.Textbox(label="DeepSeek API KEY", placeholder="sk-...", type="password")
            url_input = gr.Textbox(label="è§†é¢‘/æ’­å®¢é“¾æ¥", placeholder="æ”¯æŒ Bç«™ã€YouTubeã€å°å®‡å®™...")
            with gr.Row():
                btn = gr.Button("ğŸ”¥ å¼€å§‹æ”¶å‰²", variant="primary")
                clear_btn = gr.Button("ğŸ§¹ æ¸…ç©ºç¼“å­˜ (æ¢è§†é¢‘ç‚¹è¿™ä¸ª)")
        with gr.Column():
            output = gr.Markdown(label="ç”Ÿæˆçš„æ·±åº¦å¤§çº²")
    
    # ç»‘å®šå¼€å§‹è¿è¡Œ
    btn.click(fn=process_video, inputs=[api_input, url_input], outputs=output)
    
    # ç»‘å®šæ¸…ç©ºç¼“å­˜
    def clear_cache():
        for f in ["temp_audio.m4a", "raw_transcript.txt"]:
            if os.path.exists(f): os.remove(f)
        return "âœ¨ ç¼“å­˜å·²æ¸…ç†ï¼Œä¸‹æ¬¡è¿è¡Œå°†é‡æ–°ä¸‹è½½éŸ³é¢‘å’Œè¯†åˆ«æ–‡å­—ã€‚"
    clear_btn.click(fn=clear_cache, outputs=output)

if __name__ == "__main__":
    # share=True ä¼šç”Ÿæˆå…¬ç½‘é“¾æ¥
    demo.launch(share=True, debug=True)
