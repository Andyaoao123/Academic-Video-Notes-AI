import os, whisper, yt_dlp
from openai import OpenAI
from google.colab import files
import markdown
from IPython.display import display, HTML

# --- å¤–éƒ¨æ¥å£åŒº ---
API_KEY = "sk-placeholder"
VIDEO_URL = "url-placeholder"

def run_podcast_tool():
    if "placeholder" in API_KEY or "placeholder" in VIDEO_URL:
        print("âŒ é”™è¯¯ï¼šè¯·å…ˆåœ¨ Colab ä¸­è®¾ç½® main.API_KEY å’Œ main.VIDEO_URL")
        return

    try:
        # 1. ä¸‹è½½éŸ³é¢‘
        print(f"ğŸ“¥ æ­£åœ¨æŠ“å–éŸ³é¢‘...")
        if os.path.exists("temp_audio.m4a"): os.remove("temp_audio.m4a")
        
        ydl_opts = {
            'format': 'm4a/bestaudio/best',
            'outtmpl': 'temp_audio.%(ext)s',
            'postprocessors': [{
                'key': 'FFmpegExtractAudio',
                'preferredcodec': 'm4a',
            }],
        }
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            ydl.download([VIDEO_URL])
        
        # 2. è½¬å½•
        print("ğŸ™ï¸ Whisper æ­£åœ¨ç²¾å‡†å¬å†™...")
        model = whisper.load_model("base") 
        result = model.transcribe("temp_audio.m4a")
        
        # 3. è¯­ä¹‰æ•´ç† (å…¨èƒ½é€šç”¨çº é”™é€»è¾‘)
        print("ğŸ” æ­£åœ¨è¿›è¡Œè¯­ä¹‰æ•´å½¢ (è‡ªåŠ¨çº é”™ã€æ–­å¥ã€å»åºŸè¯)...")
        correction_prompt = f"""
        ä½ æ˜¯ä¸€ä½ç²¾é€šä¸­æ–‡è¯­å¢ƒçš„èµ„æ·±ç¼–è¾‘ã€‚è¯·å¯¹ä»¥ä¸‹æ‚ä¹±çš„è¯­éŸ³è½¬æ–‡å­—ç¨¿è¿›è¡Œâ€œæ·±åº¦é‡å¡‘â€ï¼š
        
        è¦æ±‚ï¼š
        1. ã€åŠ æ ‡ç‚¹ä¸æ–­å¥ã€‘ï¼šæ ¹æ®è¯­ä¹‰é€»è¾‘æ·»åŠ ç²¾å‡†çš„æ ‡ç‚¹ç¬¦å·ã€‚ä¸¥ç¦å‡ºç°è¶…è¿‡15å­—è€Œæ²¡æœ‰æ ‡ç‚¹çš„â€œé•¿é¾™å¥â€ï¼Œç¡®ä¿äººç±»é˜…è¯»èŠ‚å¥æ„Ÿã€‚
        2. ã€å…¨èƒ½çº é”™ã€‘ï¼šç»“åˆå…¨ç¯‡ä¸Šä¸‹æ–‡ï¼Œè‡ªåŠ¨ä¿®æ­£æ‰€æœ‰ç”±äºå‘éŸ³ç›¸ä¼¼å¯¼è‡´çš„è¯†åˆ«é”™è¯¯ï¼ˆåŒ…æ‹¬ä½†ä¸é™äºä¸“æœ‰åè¯ã€åŒ»å­¦æœ¯è¯­ã€å£è¯­è°éŸ³ï¼‰ã€‚
        3. ã€å»é™¤å£è¯­èµ˜è¯ã€‘ï¼šå½»åº•è¿‡æ»¤æ‰â€œé‚£ä¸ªã€å°±æ˜¯ã€ç„¶åã€å‘ƒã€æˆ‘çš„è¯ã€å¯¹å§ã€æ‰€è°“çš„â€ç­‰æ¯«æ— æ„ä¹‰çš„å¡«å……è¯ã€‚
        4. ã€åˆ†æ®µå¤„ç†ã€‘ï¼šæ¯æ®µåªèšç„¦ä¸€ä¸ªæ ¸å¿ƒè¯­ä¹‰ç‚¹ï¼Œé€»è¾‘åˆ‡æ¢æ—¶å¿…é¡»æ¢è¡Œã€‚
        
        åŸå§‹ç¨¿ä»¶å†…å®¹ï¼š
        {result['text']}
        """
        
        client = OpenAI(api_key=API_KEY, base_url="https://dashscope.aliyuncs.com/compatible-mode/v1")
        corr_res = client.chat.completions.create(
            model="qwen-plus", 
            messages=[{"role": "user", "content": correction_prompt}]
        )
        corrected_text = corr_res.choices[0].message.content

        # 4. æå–æ·±åº¦é€»è¾‘å¤§çº²
        print("âœï¸ æ­£åœ¨ç”Ÿæˆæ·±åº¦æ€ç»´å¯¼å›¾å¤§çº²...")
        map_prompt = f"""
        ä½ æ˜¯ä¸€ä½é¡¶çº§çš„é€»è¾‘åˆ†æå¸ˆã€‚è¯·åŸºäºä»¥ä¸‹ã€æ•´ç†åçš„ç²¾æ’æ–‡ç¨¿ã€‘æå–æ·±åº¦é€»è¾‘å¤§çº²ã€‚
        è¦æ±‚ï¼š
        - # ä¸€çº§æ ‡é¢˜ï¼šæ’­å®¢æ ¸å¿ƒä¸»é¢˜
        - ## äºŒçº§æ ‡é¢˜ï¼šæ ¸å¿ƒé€»è¾‘æ¿å—
        - ### ä¸‰çº§æ ‡é¢˜ï¼šå…·ä½“è®ºç‚¹/å­è§‚ç‚¹
        - - åˆ—è¡¨é¡¹ï¼šç”¨ã€Œã€åŒ…è£¹çš„åŸæ–‡æ ¸å¿ƒé‡‘å¥ã€‚
        
        ç²¾æ’æ–‡ç¨¿å†…å®¹ï¼š
        {corrected_text}
        """
        map_res = client.chat.completions.create(
            model="qwen-plus", 
            messages=[{"role": "user", "content": map_prompt}]
        )
        map_content = map_res.choices[0].message.content

        # 5. ä¸‹è½½æ–‡ä»¶
        with open("1_ä¿®æ­£ç²¾æ’æ–‡ç¨¿.txt", "w", encoding="utf-8") as f: f.write(corrected_text)
        with open("2_æ·±åº¦é€»è¾‘å¤§çº².md", "w", encoding="utf-8") as f: f.write(map_content)
        files.download("1_ä¿®æ­£ç²¾æ’æ–‡ç¨¿.txt")
        files.download("2_æ·±åº¦é€»è¾‘å¤§çº².md")

        # 6. Colab é¢„è§ˆæ¸²æŸ“
        print("\n--- ğŸ“ é€»è¾‘å¤§çº²å®æ—¶é¢„è§ˆ ---")
        display(HTML(f"""
        <div style="background:#f9f9f9; padding:20px; border-radius:12px; border:1px solid #ddd; line-height:1.8;">
            {markdown.markdown(map_content)}
        </div>
        """))
        print("\nğŸ‰ ä»»åŠ¡å®Œæˆï¼ä¸¤ä¸ªæ–‡ä»¶å·²è‡ªåŠ¨ä¸‹è½½ã€‚")

    except Exception as e:
        print(f"âŒ è¿è¡ŒæŠ¥é”™: {e}")

if __name__ == "__main__":
    run_podcast_tool()
