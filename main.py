import os, whisper, yt_dlp, shutil, time
from openai import OpenAI
import gradio as gr

def process_all_in_one(api_key, input_content, harvest_mode):
    """
    ä¸‰åˆä¸€æµæ°´çº¿æ¶æ„ï¼š
    1. é›…æ€æ¨¡å¼ï¼šç›´æ¥ Agent æ‰¹æ”¹
    2. è§†é¢‘æ¨¡å¼ï¼šWhisperè¯†åˆ« -> B.æ ‡ç‚¹æ•´ç†ä¸é€»è¾‘åˆ†æ®µ -> C.åˆ†å‘(ç¿»è¯‘/å¤§çº²/çº¯æ•´ç†)
    """
    final_key = api_key if api_key and "sk-" in api_key else "sk-placeholder"
    
    # åŸºç¡€æ ¡éªŒ
    if "placeholder" in final_key:
        yield "âŒ é”™è¯¯ï¼šè¯·åœ¨ç•Œé¢è¾“å…¥æœ‰æ•ˆçš„ API_KEY", None
        return
    if not input_content.strip():
        yield "âŒ é”™è¯¯ï¼šè¾“å…¥å†…å®¹ä¸èƒ½ä¸ºç©º", None
        return

    client = OpenAI(api_key=final_key, base_url="https://dashscope.aliyuncs.com/compatible-mode/v1")
    all_summary_report = ""
    all_files = []
    
    # æ‹†åˆ†å¤šè¡Œé“¾æ¥
    lines = [l.strip() for l in input_content.split('\n') if l.strip()]

    # --- åœºæ™¯ Aï¼šé›…æ€ä½œæ–‡æ•™ç»ƒ (Agent æ¨¡å¼) ---
    if harvest_mode == "é›…æ€ä½œæ–‡æ•™ç»ƒ":
        yield "âœï¸ è€ƒå®˜æ­£åœ¨ç ”è¯»ä½ çš„å¤§ä½œï¼Œå‡†å¤‡ç»™å‡ºå³æ—¶åé¦ˆ...", None
        ielts_p = f"""ä»»åŠ¡ï¼šè¯·ä½œä¸ºä¸€åæ‹¥æœ‰15å¹´ç»éªŒçš„é›…æ€èµ„æ·±å‰è€ƒå®˜ï¼Œå¯¹ä»¥ä¸‹ä½œæ–‡è¿›è¡Œæ·±åº¦æ‰¹æ”¹ã€‚
è¦æ±‚ï¼š
1. ã€é¢„ä¼°åˆ†å€¼ã€‘ï¼šç»™å‡ºæ€»åˆ†åŠå››ä¸ªå•é¡¹ï¼ˆTR/CC/LR/GRAï¼‰çš„é¢„ä¼°åˆ†ã€‚
2. ã€é€»è¾‘æ¼æ´ã€‘ï¼šæŒ‡å‡ºæ–‡ç« è®ºè¯ä¸ä¸¥å¯†æˆ–è¡”æ¥çªå…€çš„åœ°æ–¹ã€‚
3. ã€è¯æ±‡å‡çº§ã€‘ï¼šæ‰¾å‡ºæ–‡ä¸­3-5ä¸ªé«˜çº§å­¦æœ¯è¯æ±‡æ›¿æ¢æ–¹æ¡ˆã€‚
4. ã€è¯­æ³•çº é”™ã€‘ï¼šä¿®æ­£é”™è¯¯å¹¶è§£é‡ŠåŸå› ã€‚
5. ã€é«˜åˆ†èŒƒæ–‡ã€‘ï¼šæä¾›ä¸€ä»½ 8 åˆ†å‚è€ƒèŒƒæ–‡ã€‚
è¯­æ°”ï¼šå¹½é»˜ä¸”çŠ€åˆ©ã€‚

å¾…æ‰¹æ”¹ä½œæ–‡ï¼š
{input_content}"""
        
        try:
            res = client.chat.completions.create(model="qwen-plus", messages=[{"role": "user", "content": ielts_p}])
            feedback = res.choices[0].message.content
            f_name = "é›…æ€ä½œæ–‡æ‰¹æ”¹æŠ¥å‘Š.txt"
            with open(f_name, "w", encoding="utf-8") as f: f.write(feedback)
            yield feedback, [f_name]
        except Exception as e:
            yield f"âŒ æ‰¹æ”¹å¤±è´¥: {str(e)}", None
        return

    # --- åœºæ™¯ Bï¼šè§†é¢‘å¤„ç†æµæ°´çº¿ ---
    for idx, url in enumerate(lines):
        header = f"### ğŸ“º æ­£åœ¨å¤„ç† ({idx+1}/{len(lines)}): {url}\n"
        yield all_summary_report + header + "æ­£åœ¨å¯åŠ¨...", all_files
        
        try:
            audio_file = f"temp_audio_{idx}.m4a"
            txt_cache = f"raw_{idx}.txt"
            
            # 1. è¯­éŸ³è¯†åˆ« (Whisper)
            if not os.path.exists(audio_file):
                yield all_summary_report + header + "ğŸ“¥ æ­£åœ¨æŠ“å–éŸ³é¢‘...", all_files
                opts = {
                    'format': 'm4a/bestaudio/best',
                    'outtmpl': f'temp_audio_{idx}.%(ext)s',
                    'postprocessors': [{'key': 'FFmpegExtractAudio','preferredcodec': 'm4a'}],
                    'quiet': True
                }
                with yt_dlp.YoutubeDL(opts) as ydl: ydl.download([url])

            if os.path.exists(txt_cache):
                with open(txt_cache, "r", encoding="utf-8") as f: content_text = f.read()
            else:
                yield all_summary_report + header + "ğŸ™ï¸ Whisper å¬å†™ä¸­...", all_files
                import torch
                model = whisper.load_model("base", device="cuda" if torch.cuda.is_available() else "cpu") 
                content_text = model.transcribe(audio_file)['text']
                with open(txt_cache, "w", encoding="utf-8") as f: f.write(content_text)

            # 2. æµæ°´çº¿æ ¸å¿ƒï¼šStep B - æ ‡ç‚¹è¿˜åŸä¸é€»è¾‘åˆ†æ®µ (è§£å†³â€œæ²¡æ ‡ç‚¹â€çš„ç—›ç‚¹)
            yield all_summary_report + header + "âœï¸ æ­£åœ¨è¿›è¡Œæ ‡ç‚¹è¿˜åŸä¸é€»è¾‘åˆ†æ®µ...", all_files
            clean_p = f"ä½ æ˜¯ä¸€ä½æ–‡å­—æ•´ç†å¸ˆã€‚è¯·å¯¹ä»¥ä¸‹åŸå§‹è¯­éŸ³æ–‡æœ¬è¿›è¡Œã€æ ‡ç‚¹è¿˜åŸã€‘å’Œã€é€»è¾‘åˆ†æ®µã€‘ï¼Œä¸¥ç¦åˆ å‡æˆ–æ¶¦è‰²åŸæ–‡è¯è¯­ï¼š\n\n{content_text}"
            clean_res = client.chat.completions.create(model="qwen-turbo", messages=[{"role": "user", "content": clean_p}])
            segmented_text = clean_res.choices[0].message.content

            # 3. æµæ°´çº¿æ ¸å¿ƒï¼šStep C - æ ¹æ®æ¨¡å¼è¾“å‡ºæœ€ç»ˆæˆå“
            if harvest_mode == "é€æ®µç¿»è¯‘å¯¹ç…§":
                yield all_summary_report + header + "ğŸŒ æ­£åœ¨åŸºäºæ•´ç†ç¨¿è¿›è¡Œå¯¹ç…§ç¿»è¯‘...", all_files
                trans_p = f"ä»»åŠ¡ï¼šæ–‡æœ¬é€æ®µç¿»è¯‘å¯¹ç…§ã€‚è¦æ±‚ï¼šæ ¼å¼ä¸º [åŸæ–‡æ®µè½]\n[ç¿»è¯‘æ®µè½]\n---ã€‚è¯·ç¿»è¯‘ä»¥ä¸‹å·²åˆ†æ®µæ–‡æœ¬ï¼Œç¡®ä¿ç¿»è¯‘ç²¾å‡†ä¸”ä¸æ”¹å†™åŸæ–‡ï¼š\n\n{segmented_text}"
                res = client.chat.completions.create(model="qwen-plus", messages=[{"role": "user", "content": trans_p}])
                final_result = res.choices[0].message.content
                out_f = f"video_{idx+1}_ä¸­è‹±å¯¹ç…§.txt"
            
            elif harvest_mode == "é€»è¾‘å¤§çº²æ¨¡å¼":
                yield all_summary_report + header + "ğŸ“Š æ­£åœ¨æç‚¼å¤§çº²ä¸æ€ç»´å¯¼å›¾...", all_files
                map_p = f"ä½ æ˜¯ä¸€ä½é€»è¾‘åˆ†æå¸ˆã€‚è¯·åŸºäºä»¥ä¸‹åˆ†æ®µæ–‡ç¨¿æå–å¤§çº²å’Œmermaid mindmapä»£ç ï¼Œæ ¸å¿ƒè®ºç‚¹ç”¨ã€Œã€åŒ…è£¹ï¼š\n\n{segmented_text}"
                res = client.chat.completions.create(model="qwen-plus", messages=[{"role": "user", "content": map_p}])
                final_result = res.choices[0].message.content
                out_f = f"video_{idx+1}_é€»è¾‘å¤§çº².txt"
            
            else: # é€æ®µæ•´ç† (ä¸ç¿»è¯‘)
                final_result = segmented_text
                out_f = f"video_{idx+1}_çº¯å‡€æ•´ç†ç¨¿.txt"

            # å­˜ç›˜å¹¶æ›´æ–° UI
            with open(out_f, "w", encoding="utf-8") as f: f.write(final_result)
            all_files.append(out_f)
            all_summary_report += f"\n---\n{header}\n{final_result}\n"
            yield all_summary_report, all_files

        except Exception as e:
            all_summary_report += f"\nâŒ æŠ¥é”™: {str(e)}\n"
            yield all_summary_report, all_files

    yield all_summary_report + "\n\nâœ… æ‰€æœ‰ä»»åŠ¡å¤„ç†å®Œæˆï¼", all_files

# --- Gradio ç•Œé¢è®¾è®¡ ---
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("# ğŸ“ å­¦æœ¯/å†™ä½œå¤šåŠŸèƒ½å…¨èƒ½æ”¶å‰²æœº")
    with gr.Row():
        with gr.Column(scale=1):
            api_input = gr.Textbox(label="API KEY", type="password")
            input_box = gr.Textbox(label="è¾“å…¥åŒºåŸŸ", lines=8, placeholder="è§†é¢‘å¡«é“¾æ¥(ä¸€è¡Œä¸€ä¸ª)ï¼›ä½œæ–‡å¡«åŸæ–‡å†…å®¹")
            mode_radio = gr.Radio(
                choices=["é€»è¾‘å¤§çº²æ¨¡å¼", "é€æ®µæ•´ç†(ä¸ç¿»è¯‘)", "é€æ®µç¿»è¯‘å¯¹ç…§", "é›…æ€ä½œæ–‡æ•™ç»ƒ"], 
                value="é€æ®µæ•´ç†(ä¸ç¿»è¯‘)", 
                label="é€‰æ‹©ä½œæˆ˜æ¨¡å¼"
            )
            btn = gr.Button("ğŸš€ ç«‹å³å¤„ç†", variant="primary")
            clear_btn = gr.Button("ğŸ§¹ æ¸…ç†ç¼“å­˜æ–‡ä»¶")
        with gr.Column(scale=2):
            file_output = gr.File(label="ğŸ“¥ ä¸‹è½½ç”Ÿæˆçš„æ–‡ä»¶", file_count="multiple")
            output_md = gr.Markdown(label="ğŸ“„ å®æ—¶åé¦ˆé¢æ¿")
    
    btn.click(fn=process_all_in_one, inputs=[api_input, input_box, mode_radio], outputs=[output_md, file_output])
    
    def clear():
        for f in os.listdir():
            if f.endswith((".m4a", ".txt", ".mp4")): os.remove(f)
        return "âœ¨ ç›®å½•å·²å‡€åŒ–ï¼Œç¼“å­˜å·²æ¸…ç©ºã€‚", None
    clear_btn.click(fn=clear, outputs=[output_md, file_output])

if __name__ == "__main__":
    demo.launch(share=True, debug=True)
